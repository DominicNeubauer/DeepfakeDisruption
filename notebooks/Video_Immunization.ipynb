{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","machine_shape":"hm","mount_file_id":"1onGhAew_ReUgvcFFY5Fi0kOZECnpJC7s","authorship_tag":"ABX9TyO7lMhv/v75I5fDGmhrhkvd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Step 1: Extract the frames of the video**"],"metadata":{"id":"L58F2wQTepIB"}},{"cell_type":"markdown","source":["this part of the code was heavily inspired by https://www.youtube.com/watch?v=oOuswkbsBCU"],"metadata":{"id":"meqrw7vKyK4v"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lokfdI-seetT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710688387314,"user_tz":-60,"elapsed":3990,"user":{"displayName":"Dominic Neubauer","userId":"13306127426149880978"}},"outputId":"7e81b599-0aaa-4c5f-90b7-50b2284a4366"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n"]}],"source":["!pip install opencv-python"]},{"cell_type":"code","source":["import cv2\n","import os\n","from tqdm import tqdm"],"metadata":{"id":"xL7IFW4efg8A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["og_video = cv2.VideoCapture(\"/content/drive/MyDrive/Colab Notebooks/assets/immunized_video.mp4\") #get the video you want"],"metadata":{"id":"-ftKS-D5fm2R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fps = og_video.get(cv2.CAP_PROP_FPS) #get the fps of the video\n","fps"],"metadata":{"id":"2J_OjwQ6kxVt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710688403539,"user_tz":-60,"elapsed":2,"user":{"displayName":"Dominic Neubauer","userId":"13306127426149880978"}},"outputId":"77bc1aaa-a56a-483e-aa62-0bf09edab0a3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30.0"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["output_directory = \"/content/drive/MyDrive/Colab Notebooks/assets/Video_Frames\" #define the directory where you want the frames saved to"],"metadata":{"id":"sGTm3X5K1ran"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n = 0 #count the frames of the video\n","i = 1 #defines the frame number when saving the image\n","r = 30 #desired frame rate, adjust according to how many frames you want extracted\n","\n","all_frames = int(og_video.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","progress_bar = tqdm(total = all_frames, desc = \"Extracting Frames\", unit = \"frames\")\n","\n","while True:\n","  #ret -> true if frame was read, false if frame wasn't read\n","   ret, frame = og_video.read()\n","\n","   if not ret or frame is None:\n","        break\n","\n","   if (r * n) % fps == 0: #extract the frames one by one\n","      file_path = os.path.join(output_directory, \"{}.jpg\".format(i))\n","      cv2.imwrite(file_path, frame)\n","      progress_bar.update(1)\n","\n","      i+=1\n","\n","   n+=1\n","\n","   if ret is False:\n","      break\n","\n","#clean up\n","og_video.release()\n","cv2.destroyAllWindows()\n","progress_bar.close()"],"metadata":{"id":"OBUDDgtzlSvl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710688406990,"user_tz":-60,"elapsed":598,"user":{"displayName":"Dominic Neubauer","userId":"13306127426149880978"}},"outputId":"c744a1b8-4f37-4d3f-8d00-14729a611863"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Extracting Frames: 100%|██████████| 10/10 [00:00<00:00, 70.72frames/s]\n"]}]},{"cell_type":"markdown","source":["# **Step 2: Immunize frames**"],"metadata":{"id":"bpXpTcJaex8Z"}},{"cell_type":"markdown","source":["This section of the code was heavily inspired by https://github.com/MadryLab/photoguard.git"],"metadata":{"id":"AOzv27tl2B2_"}},{"cell_type":"markdown","source":["2.1 Prequisites"],"metadata":{"id":"Fa9gd2zXfbXF"}},{"cell_type":"code","source":["from PIL import Image, ImageOps\n","import requests\n","import numpy as np\n","import torch\n","import torchvision.transforms as T"],"metadata":{"id":"1-Ve9YUrmzQW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!huggingface-cli login"],"metadata":{"id":"5PONBQEznIOM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install diffusers"],"metadata":{"id":"0O1dTPaNn2sw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from diffusers import StableDiffusionImg2ImgPipeline"],"metadata":{"id":"fCNj77GVn4IS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["to_pil = T.ToPILImage()"],"metadata":{"id":"XZE0jFAJw3af"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2.2 Collect images in a batch"],"metadata":{"id":"KwxgryZTgc5O"}},{"cell_type":"markdown","source":["Batch processing code was inspired by https://www.dzyla.com/blog/post34/"],"metadata":{"id":"h3xY8n9yy8NY"}},{"cell_type":"code","source":["input_folder = \"/content/drive/MyDrive/Colab Notebooks/assets/Video_Frames\"\n","\n","def getFrames(input_folder):\n","\n","    frames = []\n","\n","    for filename in os.listdir(input_folder):\n","        frame_path = os.path.join(input_folder, filename) #creates a full path for each frame\n","        #https://docs.python.org/3/library/os.html#module-os citation\n","\n","        if os.path.isfile(frame_path):\n","            frame = Image.open(frame_path).convert('RGB')\n","            frames.append(frame)\n","\n","    return frames"],"metadata":{"id":"9jCTVfTP21Tl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2.3 Crop and Resize the images"],"metadata":{"id":"Rl7k6qZHgg4R"}},{"cell_type":"code","source":["#adjust the cropping depending on your video\n","def resizeFrames(frames, input_folder, output_folder):\n","\n","    resize = T.transforms.Resize(512)\n","\n","    for i, init_image in enumerate(tqdm(frames, desc=\"Processing Images\")):\n","\n","        init_image_resized = resize(init_image)\n","        width, height = init_image_resized.size\n","\n","        right_crop = init_image_resized.crop((width - 512, 0, width, height))\n","\n","        output_path = os.path.join(output_folder, f\"cropped{(i+1)}.jpg\")\n","\n","        right_crop.save(output_path)\n","\n"],"metadata":{"id":"TqyEp7w8n5la"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_folder = \"/content/drive/MyDrive/Colab Notebooks/assets/Video_Frames\"\n","output_folder = \"/content/drive/MyDrive/Colab Notebooks/assets/Cropped_Frames\"\n","images = getFrames(input_folder)\n","resizeFrames(images, input_folder, output_folder)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ipegPLYR5Emy","executionInfo":{"status":"ok","timestamp":1710685850321,"user_tz":-60,"elapsed":50744,"user":{"displayName":"Dominic Neubauer","userId":"13306127426149880978"}},"outputId":"5e1598b2-7463-4fbf-85f1-54fdfcb8d137"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing Images: 100%|██████████| 49/49 [00:09<00:00,  5.03it/s]\n"]}]},{"cell_type":"markdown","source":["2.4 Preprocess images"],"metadata":{"id":"9KMqaZdwgk_4"}},{"cell_type":"code","source":["def preprocess(image):\n","    #resize the image to be compatible with the model input\n","    width, height = image.size\n","    width, height = map(lambda x: x - x % 32, (width, height))  #Many deep learning models especially those based on CNNs work efficiently with input sizes that are multiples of 32 that's why resize to an integer multiple of 32\n","    image = image.resize((width, height), resample=Image.LANCZOS) #Resampling using the Lanczos filter helps preserve image details\n","    image = np.array(image).astype(np.float32) / 255.0 #converts the image to a numpy array, changes the data type to float32 for precision and normalizes pixel values to the range [0, 1] by dividing by 255, this helps stabilize the training process\n","    #numpy array for high-performance multidimensional object management\n","    image = image[None].transpose(0, 3, 1, 2) #adding a singleton dimension at the beginning using None to be compatible with the expected input format\n","    image = torch.from_numpy(image) #converts the numpy array to a PyTorch tensor\n","    return 2.0 * image - 1.0 #scales pixel values to the range [-1, 1] for model input"],"metadata":{"id":"uk05RpQfzccx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2.5 PGD Attack"],"metadata":{"id":"s5seZdxJgoGg"}},{"cell_type":"code","source":["#initialize the model\n","\n","device = \"cuda\"\n","model_id_or_path = \"runwayml/stable-diffusion-v1-5\"\n","pipe_img2img = StableDiffusionImg2ImgPipeline.from_pretrained(model_id_or_path, torch_dtype=torch.float16)\n","pipe_img2img = pipe_img2img.to(device)"],"metadata":{"id":"0hmBLv6Aw5iO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def pgd(X, model, eps=0.1, step_size=0.015, iters=40, clamp_min=0, clamp_max=1):\n","    # clamp_min=0 and clamp_max=1 are to keep the pixel values at [0, 1]\n","    # Initialize adversarial examples with random noise\n","    X_adv = X.clone().detach() + (torch.rand(*X.shape) * 2 * eps - eps).cuda()\n","    # detach() is used to ensure that the created copy does not track gradient history\n","    # torch.rand(*X.shape) Generates a tensor of random values with the same shape as X\n","    # * 2 * eps - eps scales and shifts the random values to have a uniform distribution\n","\n","    pbar = tqdm(range(iters))\n","    for i in pbar:\n","        actual_step_size = step_size - (step_size - step_size / 100) / iters * i #decreases step size dynamically to reduce perturbation magnitude\n","\n","        X_adv.requires_grad_(True) #enables the computation of gradients, crucial for gradient descent attack\n","\n","        # Modify loss function to target specific features or representations\n","\n","        loss = (model(X_adv).latent_dist.mean).norm()\n","\n","        pbar.set_description(f\"[Running attack]: Loss {loss.item():.5f} | step size: {actual_step_size:.4}\") #progress bar\n","\n","        grad, = torch.autograd.grad(loss, [X_adv])\n","\n","        # Perturb the image based on the gradient\n","        X_adv = X_adv - grad.detach().sign() * actual_step_size #.detach() prevents further gradient computations during updates and .sign() maximizes loss\n","        X_adv = torch.minimum(torch.maximum(X_adv, X - eps), X + eps )#The values of the adversarial example are clamped to ensure that they stay within a feasible range to prevent the generation of adversarial examples that are too different from the original input.\n","        X_adv.data = torch.clamp(X_adv, min=clamp_min, max=clamp_max) #ensures that each element remains in [0,1]\n","        X_adv.grad = None #clears any accumulated gradient information from previous iterations\n","\n","\n","    return X_adv"],"metadata":{"id":"CCEjDrfWw_6u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["immunized_output_folder = \"/content/drive/MyDrive/Colab Notebooks/assets/Immunized_Frames\""],"metadata":{"id":"zR92SvlnVUbM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2.7 Execute the attack"],"metadata":{"id":"pOS4AEcYgrND"}},{"cell_type":"code","source":["i = 1\n","\n","for filename in os.listdir(output_folder):\n","    frame_path = os.path.join(output_folder, filename)\n","\n","\n","    #Load and preprocess the image\n","    init_image = Image.open(frame_path).convert('RGB')\n","    with torch.autocast('cuda'):\n","        X = preprocess(init_image).half().cuda()\n","\n","        #Execute PGD attack\n","        adv_X = pgd(X,\n","                    model=pipe_img2img.vae.encode,\n","                    clamp_min=-1,\n","                    clamp_max=1,\n","                    eps=0.2,  #Adjust the perturbation range for more noticeable disruptions\n","                    step_size=0.000001,\n","                    iters=500,\n","                   )\n","\n","        # Convert pixels back to [0, 1] range\n","        adv_X = (adv_X / 2 + 0.5).clamp(0, 1)\n","\n","    adv_image = to_pil(adv_X[0]).convert(\"RGB\")\n","\n","    #output path\n","    immunized_frame_path = os.path.join(immunized_output_folder, f\"immunized_{i}.jpg\")\n","\n","    #save the new image\n","    adv_image.save(immunized_frame_path)\n","\n","    i += 1\n"],"metadata":{"id":"KNEF2kwF3ted","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710686461838,"user_tz":-60,"elapsed":504641,"user":{"displayName":"Dominic Neubauer","userId":"13306127426149880978"}},"outputId":"5781aef2-f871-4e2d-8db4-170455eb8328"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[Running attack]: Loss 679.84784 | step size: 1.198e-08: 100%|██████████| 500/500 [00:51<00:00,  9.68it/s]\n","[Running attack]: Loss 678.29138 | step size: 1.198e-08: 100%|██████████| 500/500 [00:49<00:00, 10.07it/s]\n","[Running attack]: Loss 679.31622 | step size: 1.198e-08: 100%|██████████| 500/500 [00:49<00:00, 10.10it/s]\n","[Running attack]: Loss 680.53479 | step size: 1.198e-08: 100%|██████████| 500/500 [00:49<00:00, 10.11it/s]\n","[Running attack]: Loss 679.71991 | step size: 1.198e-08: 100%|██████████| 500/500 [00:49<00:00, 10.12it/s]\n","[Running attack]: Loss 680.01361 | step size: 1.198e-08: 100%|██████████| 500/500 [00:49<00:00, 10.13it/s]\n","[Running attack]: Loss 680.99133 | step size: 1.198e-08: 100%|██████████| 500/500 [00:49<00:00, 10.14it/s]\n","[Running attack]: Loss 679.99615 | step size: 1.198e-08: 100%|██████████| 500/500 [00:49<00:00, 10.08it/s]\n","[Running attack]: Loss 679.27246 | step size: 1.198e-08: 100%|██████████| 500/500 [00:49<00:00, 10.12it/s]\n","[Running attack]: Loss 679.92041 | step size: 1.198e-08: 100%|██████████| 500/500 [00:49<00:00, 10.12it/s]\n"]}]},{"cell_type":"markdown","source":["# **Step 3: Reassamble frames**"],"metadata":{"id":"9yj4DlGae4M2"}},{"cell_type":"markdown","source":["this part of the code was heavily inspired by https://www.youtube.com/watch?v=ZcqodhMuv4o"],"metadata":{"id":"a2hY19lxyHm2"}},{"cell_type":"code","source":["input_directory = \"/content/drive/MyDrive/Colab Notebooks/assets/Immunized_Frames\" #directory containing immunized frames\n","\n","output_directory = \"/content/drive/MyDrive/Colab Notebooks/assets/\" #output directory\n","\n","output_name = \"immunized_video.mp4\" #output\n","\n","combined = output_directory + output_name"],"metadata":{"id":"KBMYeL0NhbOK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fps = 30 #specify the frame rate, should be the same as the original video\n","\n","format = cv2.VideoWriter_fourcc(*\"mp4v\") #desired video codec\n","size = (512, 512) #size of the video (width, length)\n","\n","immunized_video = cv2.VideoWriter(combined, format, fps, size)"],"metadata":{"id":"KpESxoeFix5F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i = 1 #frame number\n","\n","all_frames = sum(1 for _ in os.listdir(input_directory))\n","\n","\n","#iterate through the frames and append them\n","progress_bar = tqdm(total = all_frames, desc = \"Processing Frames\", unit = \"frames\")\n","\n","while True:\n","  file_path = os.path.join(input_directory, \"immunized_{}.jpg\".format(i))\n","\n","  if not os.path.exists(file_path):\n","     break\n","\n","\n","  frame = cv2.imread(file_path)\n","  immunized_video.write(frame)\n","\n","  progress_bar.update(1)  # Update the progress bar\n","  progress_bar.set_postfix({\"Frame\": i})\n","\n","  i+=1\n","\n","immunized_video.release()\n","\n","cv2.destroyAllWindows()\n","\n","#obviously the end result doesn't have any audio because it's just a compilation of images, neglecting any accompanying sound elements"],"metadata":{"id":"D9RYeyIHjP3D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710686512740,"user_tz":-60,"elapsed":555,"user":{"displayName":"Dominic Neubauer","userId":"13306127426149880978"}},"outputId":"0d3cd652-d016-4eb5-d1b6-43e7635c802d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing Frames: 100%|██████████| 10/10 [00:00<00:00, 38.38frames/s, Frame=10]"]}]}]}